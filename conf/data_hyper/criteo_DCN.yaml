model:
  batch_norm: False
  crossing_layers: 4
  dnn_hidden_units: [1000, 1000, 1000, 1000, 1000]
  dnn_activations: relu
  embedding_dim: 16
  embedding_dropout: 0
  embedding_regularizer: 1.0e-05
  net_regularizer: 0
  net_dropout: 0.2

optim:
  lr: 0.001